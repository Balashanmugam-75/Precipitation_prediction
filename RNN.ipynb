{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cuBgeOfCObPj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error,r2_score\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.stattools import adfuller, kpss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "l65ePVTSqyKl"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "u8-jQ6ILOh_S",
        "outputId": "14320171-fa63-4a49-e5f4-26a261532e1a"
      },
      "outputs": [],
      "source": [
        "raw_data = pd.read_csv('All_tnj_rain_gauge_daily.csv')\n",
        "raw_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpmv0abcOh8X",
        "outputId": "f2b81949-628d-47ef-dee9-9d8b7e4821a6"
      },
      "outputs": [],
      "source": [
        "raw_data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap9inCBeOh5e",
        "outputId": "d5ac7fb9-be47-4968-8efc-0c97961e5505"
      },
      "outputs": [],
      "source": [
        "raw_data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3umkThXgOh2o"
      },
      "outputs": [],
      "source": [
        "raw_data.fillna(raw_data.mean(),inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77DOnhrKOhzV",
        "outputId": "ed5d6b36-64aa-4547-cc56-cf6ba18069b0"
      },
      "outputs": [],
      "source": [
        "raw_data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GImNkpckOhkZ"
      },
      "outputs": [],
      "source": [
        "date = []\n",
        "for i in range(len(raw_data['YEAR'])):\n",
        "  date.append(str(raw_data['YEAR'][i])+'/'+str(raw_data['MO'][i])+'/'+str(raw_data['DY'][i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "C79hI4pzOhiF"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame()\n",
        "df = raw_data.drop(['YEAR','MO','DY'],axis=1)\n",
        "df['DATE'] = pd.to_datetime(date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NS6Lf3MEOher",
        "outputId": "1dd34497-c891-4fe4-b002-eda5ddb33778"
      },
      "outputs": [],
      "source": [
        "df2 =  df.copy()\n",
        "\n",
        "df2['DATE'] = pd.to_datetime(df2['DATE'])\n",
        "\n",
        "df2.set_index('DATE', inplace=True)\n",
        "\n",
        "alpha = 0.05\n",
        "\n",
        "\n",
        "sample_size = 1000\n",
        "\n",
        "\n",
        "sampled_data = df2.sample(n=sample_size, random_state=42)\n",
        "\n",
        "\n",
        "kpss_result = kpss(sampled_data['PRECTOTCORR'])\n",
        "kpss_statistic, kpss_pvalue, _, kpss_crit_values = kpss_result\n",
        "print(\"Kwiatkowski-Phillips-Schmidt-Shin (KPSS) Test (Sampled Data):\")\n",
        "print(f\"KPSS Statistic: {kpss_statistic}\")\n",
        "print(f\"P-value: {kpss_pvalue}\")\n",
        "print(\"Critical Values:\")\n",
        "for key, value in kpss_crit_values.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "if kpss_pvalue <= alpha:\n",
        "    print(\"Result: Reject null hypothesis, trend is not present (stationary).\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject null hypothesis, trend is present (non-stationary).\")\n",
        "\n",
        "\n",
        "adf_result = adfuller(sampled_data['PRECTOTCORR'])\n",
        "adf_statistic = adf_result[0]\n",
        "adf_critical_values = adf_result[4]\n",
        "\n",
        "print(\"Augmented Dickey-Fuller (ADF) Test (Sampled Data):\")\n",
        "print(f\"ADF Statistic: {adf_statistic}\")\n",
        "\n",
        "if adf_statistic < adf_critical_values['5%']:\n",
        "    print(\"Result: Reject null hypothesis, trend is present (non-stationary).\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject null hypothesis, trend is not present (stationary).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "id": "VNHhVivfOhcF",
        "outputId": "c578c63f-5f84-4327-f447-abe7474d143b"
      },
      "outputs": [],
      "source": [
        "df1 = df.copy()\n",
        "\n",
        "df1['DATE'] = pd.to_datetime(df1['DATE'])\n",
        "\n",
        "\n",
        "df1.set_index('DATE', inplace=True)\n",
        "\n",
        "\n",
        "df1 = df1.resample('M').sum()\n",
        "\n",
        "\n",
        "result = sm.tsa.seasonal_decompose(df1['PRECTOTCORR'], model='additive')\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(411)\n",
        "plt.plot(df1['PRECTOTCORR'], label='Original')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(412)\n",
        "plt.plot(result.trend, label='Trend')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(413)\n",
        "plt.plot(result.seasonal, label='Seasonal')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(414)\n",
        "plt.plot(result.resid, label='Residual')\n",
        "plt.legend(loc='best')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7ozbtZqQOhZB"
      },
      "outputs": [],
      "source": [
        "selected_columns = ['T2M', 'T2MDEW', 'T2M_MAX', 'T2M_MIN', 'RH2M', 'PS', 'WS10M', 'PRECTOTCORR']\n",
        "data = df[selected_columns].values\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "data = scaler.fit_transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AOnfGF8KOhWQ"
      },
      "outputs": [],
      "source": [
        "train_size = int(len(data) * 0.8)\n",
        "train_data, test_data = data[:train_size], data[train_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7K7XFOusOhTF"
      },
      "outputs": [],
      "source": [
        "def create_sequences(data, look_back=1):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - look_back):\n",
        "        X.append(data[i:(i + look_back), :-1])\n",
        "        y.append(data[i + look_back, -1])\n",
        "    return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dD2dC6weOhQK"
      },
      "outputs": [],
      "source": [
        "look_back = 10\n",
        "trainX, trainY = create_sequences(train_data, look_back)\n",
        "testX, testY = create_sequences(test_data, look_back)\n",
        "\n",
        "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], trainX.shape[2]))\n",
        "testX = np.reshape(testX, (testX.shape[0], testX.shape[1], testX.shape[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WGjCDeZKOhNK"
      },
      "outputs": [],
      "source": [
        "def objective_function(hyperparameters):\n",
        "    rnn_units = hyperparameters['rnn_units']\n",
        "    optimizer = 'adam'\n",
        "    epochs = hyperparameters['epochs']\n",
        "    batch_size = hyperparameters['batch_size']\n",
        "\n",
        "    # Create and compile the LSTM model with the given hyperparameters\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.SimpleRNN(rnn_units, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(trainX, trainY, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = model.predict(testX)\n",
        "\n",
        "    # Calculate the RMSE as the evaluation metric\n",
        "    rmse = np.sqrt(mean_squared_error(testY, y_pred))\n",
        "    print(rmse)\n",
        "\n",
        "    return rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWbKdiiCOhKQ",
        "outputId": "98f85d99-62d8-4bcb-fd70-525a56802495"
      },
      "outputs": [],
      "source": [
        "population_size = 6\n",
        "max_iterations = 2\n",
        "\n",
        "# Define the search space for hyperparameters\n",
        "search_space = {\n",
        "    'rnn_units': [32, 64, 128],\n",
        "    'epochs': [40, 50],\n",
        "    'batch_size': [64, 128],\n",
        "    # Add more hyperparameters and their ranges here\n",
        "}\n",
        "\n",
        "# Initialize the population with random hyperparameters\n",
        "population = [{'rnn_units': np.random.choice(search_space['rnn_units']),\n",
        "              'epochs': np.random.choice(search_space['epochs']),\n",
        "              'batch_size': np.random.choice(search_space['batch_size'])} for _ in range(population_size)]\n",
        "\n",
        "for iteration in range(max_iterations):\n",
        "    # Calculate fitness values for each set of hyperparameters in the population\n",
        "    fitness = [objective_function(hyperparameters) for hyperparameters in population]\n",
        "\n",
        "    # Find the best and worst solutions in the population\n",
        "    best_index = np.argmin(fitness)\n",
        "    worst_index = np.argmax(fitness)\n",
        "\n",
        "    # Update the position of the Harris hawks (i.e., update hyperparameters)\n",
        "    for i in range(population_size):\n",
        "        if i != best_index:\n",
        "            E0 = np.random.rand()  # Random exploration factor\n",
        "            E1 = 2 * np.random.rand() - 1  # Random exploration factor\n",
        "            E2 = 2 * np.random.rand() - 1  # Random exploration factor\n",
        "            E3 = 2 * np.random.rand() - 1  # Random exploration factor\n",
        "\n",
        "            if fitness[i] > fitness[best_index]:\n",
        "                for param in search_space.keys():\n",
        "                    population[i][param] = int(population[i][param]) + int(E0 * (int(population[best_index][param]) - int(population[i][param])))\n",
        "            if fitness[i] < fitness[best_index]:\n",
        "                for param in search_space.keys():\n",
        "                    population[i][param] = int(population[i][param]) + int(E1 * (int(population[i][param]) - int(population[best_index][param])))\n",
        "\n",
        "            if i != worst_index:\n",
        "              distance = np.linalg.norm(np.array(list(population[worst_index].values())) - np.array(list(population[i].values())))\n",
        "              if distance > 1e-6:\n",
        "                for param in search_space.keys():\n",
        "                  if isinstance(population[i][param], (int, float)):\n",
        "                    population[i][param] = int(population[i][param]) + int(E2 * (population[worst_index][param] - population[i][param]) / distance)\n",
        "                  else:\n",
        "                    population[i][param] = np.array(list(population[i][param])) + E2 * (np.array(list(population[worst_index].values())) - np.array(list(population[i].values()))) / distance\n",
        "              else:\n",
        "                for param in search_space.keys():\n",
        "                  if isinstance(population[i][param], (int, float)):\n",
        "                    population[i][param] = int(population[i][param]) + int(E3 * np.random.rand())\n",
        "                  else:\n",
        "                    population[i][param] = np.array(list(population[i][param])) + E3 * np.random.rand()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Ensure hyperparameters stay within bounds\n",
        "            for param in search_space.keys():\n",
        "              if isinstance(population[i][param], (int, float)):\n",
        "                population[i][param] = int(np.clip(population[i][param], min(search_space[param]), max(search_space[param])))\n",
        "              else:\n",
        "                population[i][param] = np.clip(population[i][param], min(search_space[param]), max(search_space[param]))\n",
        "\n",
        "# Find the best set of hyperparameters and its corresponding fitness value\n",
        "best_hyperparameters = population[best_index]\n",
        "best_fitness = fitness[best_index]\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
        "print(\"Best Fitness Value (RMSE):\", best_fitness)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEamrilkOhHP"
      },
      "outputs": [],
      "source": [
        "#units = best_hyperparameters['rnn_units']\n",
        "#epoch = best_hyperparameters['epochs']\n",
        "#batch = best_hyperparameters['batch_size']\n",
        "model_RNN = tf.keras.Sequential()\n",
        "model_RNN.add(tf.keras.layers.SimpleRNN(128, input_shape=(look_back,7)))\n",
        "model_RNN.add(tf.keras.layers.Dense(1))\n",
        "model_RNN.compile(loss='mean_squared_error', optimizer='adam')\n",
        "history_RNN = model_RNN.fit(trainX, trainY,validation_data=(testX,testY), epochs=50, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ta0jYETDPQ0L"
      },
      "outputs": [],
      "source": [
        "trainPredict = model_RNN.predict(trainX)\n",
        "testPredict = model_RNN.predict(testX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypiU5iu5PQxl"
      },
      "outputs": [],
      "source": [
        "trainScore = np.sqrt(mean_squared_error(trainY, trainPredict))\n",
        "testScore = np.sqrt(mean_squared_error(testY, testPredict))\n",
        "print(f'Train RMSE: {trainScore:.2f}')\n",
        "print(f'Test RMSE: {testScore:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-M3wV9cNPQu0"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.plot(history_RNN.history['loss'],label=\"LOSS\")\n",
        "plt.plot(history_RNN.history['val_loss'],label = \"VALIDATION LOSS\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Zt2d1MQPQsT"
      },
      "outputs": [],
      "source": [
        "plt.plot(testY)\n",
        "plt.plot(testPredict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lJI8DgUPQpl"
      },
      "outputs": [],
      "source": [
        "mse = mean_squared_error(testY,testPredict)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(testY,testPredict)\n",
        "r2 = r2_score(testY,testPredict)\n",
        "mbd = np.mean(testPredict - testY)\n",
        "print(f\"mean squared error: {mse}\")\n",
        "print(f\"root mean squared error: {rmse}\")\n",
        "print(f\"mean absolute error: {mae}\")\n",
        "print(f\"mean bias deviation {mbd}\")\n",
        "print(f\"r2_score: {r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3XJ2AfrPQl-"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame()\n",
        "df['Model'] = 'LSTM'\n",
        "df['MSE'] = mse\n",
        "df['MAE'] =  mae\n",
        "df['MBD'] = mbd\n",
        "df['R2'] = r2\n",
        "\n",
        "df.to_csv(\"LSTM.csv\",index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
