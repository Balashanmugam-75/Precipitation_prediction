{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Wy5KbnLWXCpu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error,r2_score\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.stattools import adfuller, kpss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wzQAoGOHqrUQ"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v-Zr3VnhAYim",
        "outputId": "a7882ed5-6d76-4cd1-ac33-1453f6868389"
      },
      "outputs": [],
      "source": [
        "raw_data = pd.read_csv('All_tnj_rain_gauge_daily.csv')\n",
        "raw_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGzFsF8dAYgV",
        "outputId": "ed1d508d-9d3e-4589-ace4-70a3a2c00659"
      },
      "outputs": [],
      "source": [
        "raw_data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoVTNoLnAYdf",
        "outputId": "199ea5ba-04ff-4ead-c9ed-428b7dcc267d"
      },
      "outputs": [],
      "source": [
        "raw_data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "p0UVJtVTAYa4"
      },
      "outputs": [],
      "source": [
        "raw_data.fillna(raw_data.mean(),inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPp2dkvvAYYn",
        "outputId": "7404895c-90bb-4e9c-98ed-fe31a41691ed"
      },
      "outputs": [],
      "source": [
        "raw_data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OF7Cw-ffAYVl"
      },
      "outputs": [],
      "source": [
        "date = []\n",
        "for i in range(len(raw_data['YEAR'])):\n",
        "  date.append(str(raw_data['YEAR'][i])+'/'+str(raw_data['MO'][i])+'/'+str(raw_data['DY'][i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "555tMahiAYQr"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame()\n",
        "df = raw_data.drop(['YEAR','MO','DY'],axis=1)\n",
        "df['DATE'] = pd.to_datetime(date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaVPvWG1AYOs",
        "outputId": "8e852f7a-6e3e-4957-d0b0-e738262888cf"
      },
      "outputs": [],
      "source": [
        "df2 =  df.copy()\n",
        "\n",
        "df2['DATE'] = pd.to_datetime(df2['DATE'])\n",
        "\n",
        "df2.set_index('DATE', inplace=True)\n",
        "\n",
        "alpha = 0.05\n",
        "\n",
        "\n",
        "sample_size = 1000\n",
        "\n",
        "\n",
        "sampled_data = df2.sample(n=sample_size, random_state=42)\n",
        "\n",
        "\n",
        "kpss_result = kpss(sampled_data['PRECTOTCORR'])\n",
        "kpss_statistic, kpss_pvalue, _, kpss_crit_values = kpss_result\n",
        "print(\"Kwiatkowski-Phillips-Schmidt-Shin (KPSS) Test (Sampled Data):\")\n",
        "print(f\"KPSS Statistic: {kpss_statistic}\")\n",
        "print(f\"P-value: {kpss_pvalue}\")\n",
        "print(\"Critical Values:\")\n",
        "for key, value in kpss_crit_values.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "if kpss_pvalue <= alpha:\n",
        "    print(\"Result: Reject null hypothesis, trend is not present (stationary).\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject null hypothesis, trend is present (non-stationary).\")\n",
        "\n",
        "\n",
        "adf_result = adfuller(sampled_data['PRECTOTCORR'])\n",
        "adf_statistic = adf_result[0]\n",
        "adf_critical_values = adf_result[4]\n",
        "\n",
        "print(\"Augmented Dickey-Fuller (ADF) Test (Sampled Data):\")\n",
        "print(f\"ADF Statistic: {adf_statistic}\")\n",
        "\n",
        "if adf_statistic < adf_critical_values['5%']:\n",
        "    print(\"Result: Reject null hypothesis, trend is present (non-stationary).\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject null hypothesis, trend is not present (stationary).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "id": "exBzK-_sAYMX",
        "outputId": "0c6dcd75-4935-442a-f9cc-0c7940980344"
      },
      "outputs": [],
      "source": [
        "df1 = df.copy()\n",
        "\n",
        "df1['DATE'] = pd.to_datetime(df1['DATE'])\n",
        "\n",
        "\n",
        "df1.set_index('DATE', inplace=True)\n",
        "\n",
        "\n",
        "df1 = df1.resample('M').sum()\n",
        "\n",
        "\n",
        "result = sm.tsa.seasonal_decompose(df1['PRECTOTCORR'], model='additive')\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(411)\n",
        "plt.plot(df1['PRECTOTCORR'], label='Original')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(412)\n",
        "plt.plot(result.trend, label='Trend')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(413)\n",
        "plt.plot(result.seasonal, label='Seasonal')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(414)\n",
        "plt.plot(result.resid, label='Residual')\n",
        "plt.legend(loc='best')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4CmvHAAdAYJw"
      },
      "outputs": [],
      "source": [
        "selected_columns = ['T2M', 'T2MDEW', 'T2M_MAX', 'T2M_MIN', 'RH2M', 'PS', 'WS10M', 'PRECTOTCORR']\n",
        "data = df[selected_columns].values\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "data = scaler.fit_transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1vchnf0hAYHk"
      },
      "outputs": [],
      "source": [
        "train_size = int(len(data) * 0.8)\n",
        "train_data, test_data = data[:train_size], data[train_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NF1iiOFEAYFX"
      },
      "outputs": [],
      "source": [
        "def create_sequences(data, look_back=1):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - look_back):\n",
        "        X.append(data[i:(i + look_back), :-1])\n",
        "        y.append(data[i + look_back, -1])\n",
        "    return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oIqVV4rLAYDJ"
      },
      "outputs": [],
      "source": [
        "look_back = 10\n",
        "trainX, trainY = create_sequences(train_data, look_back)\n",
        "testX, testY = create_sequences(test_data, look_back)\n",
        "\n",
        "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], trainX.shape[2]))\n",
        "testX = np.reshape(testX, (testX.shape[0], testX.shape[1], testX.shape[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "vn1S8uY1AYAV"
      },
      "outputs": [],
      "source": [
        "def objective_function(hyperparameters):\n",
        "    gru_units = hyperparameters['gru_units']\n",
        "    optimizer = 'adam'\n",
        "    epochs = hyperparameters['epochs']\n",
        "    batch_size = hyperparameters['batch_size']\n",
        "\n",
        "    # Create and compile the LSTM model with the given hyperparameters\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.GRU(gru_units, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(trainX, trainY, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = model.predict(testX)\n",
        "\n",
        "    # Calculate the RMSE as the evaluation metric\n",
        "    rmse = np.sqrt(mean_squared_error(testY, y_pred))\n",
        "    print(rmse)\n",
        "\n",
        "    return rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HePHixeJAX-I",
        "outputId": "961bfa68-9ed2-45bd-8b4e-c72f2c5415c6"
      },
      "outputs": [],
      "source": [
        "population_size = 6\n",
        "max_iterations = 2\n",
        "\n",
        "# Define the search space for hyperparameters\n",
        "search_space = {\n",
        "    'gru_units': [32, 64, 128],\n",
        "    'epochs': [40, 50],\n",
        "    'batch_size': [32, 64],\n",
        "    # Add more hyperparameters and their ranges here\n",
        "}\n",
        "\n",
        "# Initialize the population with random hyperparameters\n",
        "population = [{'gru_units': np.random.choice(search_space['gru_units']),\n",
        "              'epochs': np.random.choice(search_space['epochs']),\n",
        "              'batch_size': np.random.choice(search_space['batch_size'])} for _ in range(population_size)]\n",
        "\n",
        "for iteration in range(max_iterations):\n",
        "    # Calculate fitness values for each set of hyperparameters in the population\n",
        "    fitness = [objective_function(hyperparameters) for hyperparameters in population]\n",
        "\n",
        "    # Find the best and worst solutions in the population\n",
        "    best_index = np.argmin(fitness)\n",
        "    worst_index = np.argmax(fitness)\n",
        "\n",
        "    # Update the position of the Harris hawks (i.e., update hyperparameters)\n",
        "    for i in range(population_size):\n",
        "        if i != best_index:\n",
        "            E0 = np.random.rand()  # Random exploration factor\n",
        "            E1 = 2 * np.random.rand() - 1  # Random exploration factor\n",
        "            E2 = 2 * np.random.rand() - 1  # Random exploration factor\n",
        "            E3 = 2 * np.random.rand() - 1  # Random exploration factor\n",
        "\n",
        "            if fitness[i] > fitness[best_index]:\n",
        "                for param in search_space.keys():\n",
        "                    population[i][param] = int(population[i][param]) + int(E0 * (int(population[best_index][param]) - int(population[i][param])))\n",
        "            if fitness[i] < fitness[best_index]:\n",
        "                for param in search_space.keys():\n",
        "                    population[i][param] = int(population[i][param]) + int(E1 * (int(population[i][param]) - int(population[best_index][param])))\n",
        "\n",
        "            if i != worst_index:\n",
        "              distance = np.linalg.norm(np.array(list(population[worst_index].values())) - np.array(list(population[i].values())))\n",
        "              if distance > 1e-6:\n",
        "                for param in search_space.keys():\n",
        "                  if isinstance(population[i][param], (int, float)):\n",
        "                    population[i][param] = int(population[i][param]) + int(E2 * (population[worst_index][param] - population[i][param]) / distance)\n",
        "                  else:\n",
        "                    population[i][param] = np.array(list(population[i][param])) + E2 * (np.array(list(population[worst_index].values())) - np.array(list(population[i].values()))) / distance\n",
        "              else:\n",
        "                for param in search_space.keys():\n",
        "                  if isinstance(population[i][param], (int, float)):\n",
        "                    population[i][param] = int(population[i][param]) + int(E3 * np.random.rand())\n",
        "                  else:\n",
        "                    population[i][param] = np.array(list(population[i][param])) + E3 * np.random.rand()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Ensure hyperparameters stay within bounds\n",
        "            for param in search_space.keys():\n",
        "              if isinstance(population[i][param], (int, float)):\n",
        "                population[i][param] = int(np.clip(population[i][param], min(search_space[param]), max(search_space[param])))\n",
        "              else:\n",
        "                population[i][param] = np.clip(population[i][param], min(search_space[param]), max(search_space[param]))\n",
        "\n",
        "# Find the best set of hyperparameters and its corresponding fitness value\n",
        "best_hyperparameters = population[best_index]\n",
        "best_fitness = fitness[best_index]\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
        "print(\"Best Fitness Value (RMSE):\", best_fitness)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jq2hFRI7AX70"
      },
      "outputs": [],
      "source": [
        "#units = best_hyperparameters['gru_units']\n",
        "#epoch = best_hyperparameters['epochs']\n",
        "#batch = best_hyperparameters['batch_size']\n",
        "model_GRU = tf.keras.Sequential()\n",
        "model_GRU.add(tf.keras.layers.GRU(128, input_shape=(look_back,7)))\n",
        "model_GRU.add(tf.keras.layers.Dense(1))\n",
        "model_GRU.compile(loss='mean_squared_error', optimizer='adam')\n",
        "history_GRU = model_GRU.fit(trainX, trainY,validation_data=(testX,testY), epochs=40, batch_size=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gREsJphAX42"
      },
      "outputs": [],
      "source": [
        "trainPredict = model_GRU.predict(trainX)\n",
        "testPredict = model_GRU.predict(testX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_kK43ZTAX2I"
      },
      "outputs": [],
      "source": [
        "trainScore = np.sqrt(mean_squared_error(trainY, trainPredict))\n",
        "testScore = np.sqrt(mean_squared_error(testY, testPredict))\n",
        "print(f'Train RMSE: {trainScore:.2f}')\n",
        "print(f'Test RMSE: {testScore:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nB4ExIydA1xf"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.plot(history_GRU.history['loss'],label=\"LOSS\")\n",
        "plt.plot(history_GRU.history['val_loss'],label = \"VALIDATION LOSS\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8bjfIFjA1u9"
      },
      "outputs": [],
      "source": [
        "plt.plot(testY)\n",
        "plt.plot(testPredict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qC-9Djud5s2s"
      },
      "outputs": [],
      "source": [
        "mse = mean_squared_error(testY,testPredict)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(testY,testPredict)\n",
        "r2 = r2_score(testY,testPredict)\n",
        "mbd = np.mean(testPredict - testY)\n",
        "print(f\"mean squared error: {mse}\")\n",
        "print(f\"root mean squared error: {rmse}\")\n",
        "print(f\"mean absolute error: {mae}\")\n",
        "print(f\"mean bias deviation {mbd}\")\n",
        "print(f\"r2_score: {r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikgRqAZ75soB"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame()\n",
        "df['Model'] = 'LSTM'\n",
        "df['MSE'] = mse\n",
        "df['MAE'] =  mae\n",
        "df['MBD'] = mbd\n",
        "df['R2'] = r2\n",
        "\n",
        "df.to_csv(\"GRU.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRcBpTQX6Ba-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
